## 프로젝트 보고서

마지막 수정: 25.05.30 13:41:25

CampusON 프로젝트는 대학생을 위한 AI 기반 맞춤형 튜터링 플랫폼의 개발을 목표로 한다. 최근 인공지능 기술이 빠르게 발전함에 따라, 대학 교육 현장에서는 학생별 수준 차이, 자기주도 학습의 한계, 개별 피드백 부족 등 다양한 학습 문제가 부각되고 있다. 경복대학교 빅데이터과는 이러한 문제를 기술적으로 해결하고자 CampusON 프로젝트를 기획하였다.  
이 플랫폼은 학생의 학습 이력과 진단 결과를 바탕으로 각 개인의 수준에 적합한 문제를 자동으로 추천하며, 생성형 AI(Exaone Deep)를 활용해 새로운 문제를 실시간으로 생성하여 제공한다. 학생들은 최초 이용 시 진단 테스트를 통해 자신의 전공 이해도와 학습 수준을 분석받고, 그 결과에 따라 반복 학습 및 맞춤형 문제 풀이가 가능하도록 설계되어 있다. 또한 대시보드에서는 본인의 학습 이력, 정답률, 추천 문제 현황 등을 직관적으로 확인할 수 있고, 빅데이터 기반의 분석을 통해 개별 피드백도 제공받는다.  
CampusON은 React 기반의 반응형 웹 UI, FastAPI와 PostgreSQL, pgvector를 활용한 Python 백엔드, 그리고 로컬에 배포된 AI 모델을 결합하여 장소와 시간의 제약 없이 누구나 쉽게 접근할 수 있는 교육 플랫폼을 지향한다. 이 프로젝트는 학생의 자기주도 학습 역량 강화, 실전 대비력 향상, 데이터 기반의 맞춤 피드백 제공이라는 세 가지 핵심 목표를 갖고 있다.  
CampusON 프로젝트의 주요 목표는 학생 개개인의 학습 이력과 진단 결과를 바탕으로 수준에 맞는 문제와 커리큘럼을 자동으로 추천하고, 맞춤형 학습 경험을 제공하는 데 있다. 서비스 최초 이용 시 진단 테스트를 통해 학생의 전공 이해도와 학습 수준을 분석하고, 그 결과를 기반으로 학습 경로를 설계한다. 기존 문제은행뿐만 아니라 Exaone Deep 32B 등 생성형 AI 모델을 활용해 새로운 문제를 실시간으로 생성함으로써 실전 대비력을 높인다. 학생의 풀이 이력, 정답률, 추천 문제 현황 등 학습 데이터를 시각화된 대시보드로 제공하고, 빅데이터 분석을 통해 개별 피드백을 지원한다. React 기반 반응형 웹 UI와 FastAPI, PostgreSQL, pgvector 등 최신 기술 스택을 활용해 장소와 시간의 제약 없이 누구나 쉽게 사용할 수 있는 플랫폼을 구축하며, 이러한 목표를 통해 CampusON은 대학생의 자기주도 학습 역량 강화, 실전 문제 해결 능력 향상, 그리고 데이터 기반의 맞춤 피드백 제공이라는 교육 혁신을 실현하고자 한다.  
CampusON 프로젝트의 성공 조건은 명확하고 측정 가능한 기준을 바탕으로 정의된다. 프로젝트가 합의된 일정 내에 주요 기능과 목표를 모두 구현하여 정해진 마감일을 준수해야 하며, 회원가입, 인증, 진단 테스트, AI 기반 문제 추천 및 대시보드 등 요구된 모든 핵심 기능이 정상적으로 동작하고 실제 사용자(학생, 교수 등)가 불편 없이 사용할 수 있어야 한다. 시스템의 품질 기준을 충족해야 하며, 이는 성능(응답 속도, 동시 접속 처리), 보안(개인정보 보호, 인증/인가), 데이터 무결성(변조 방지, 감사 기록), 안정성(장애 발생 시 신속한 복구) 등을 포함한다. 또한 프로젝트는 예산 내에서 진행되어야 하며, 이해관계자(학생, 교수, 학교 관리자 등)의 요구와 기대를 만족시켜야 한다. 실제 서비스 오픈 후에는 사용자 채택률, 재방문율, 긍정적인 피드백 등 실질적인 활용성과 만족도가 확보되어야 하며, 데이터 기반 피드백과 AI 추천 기능이 실질적으로 학습 효과 향상에 기여해야 한다. 마지막으로, 프로젝트 결과물이 향후 유지보수와 확장에 용이하도록 문서화 및 코드 품질이 보장되어야 하며, 관련 법률과 규정(개인정보보호, 교육 관련 규정 등)을 준수해야 한다. 이러한 기준이 충족될 때 CampusON 프로젝트는 성공적으로 완료되었다고 평가할 수 있다.  
CampusON의 전체 개발 단계는 플랫폼의 기본 구조를 학생의 학습 이력과 진단 결과를 바탕으로 개인별 수준에 맞는 문제를 추천하고, 생성형 AI(Exaone Deep)를 활용해 새로운 문제를 실시간으로 제공하는 시스템으로 설계하는 것에서 출발한다. 서비스는 React 기반의 반응형 웹 UI와 FastAPI, PostgreSQL, pgvector, 로컬 AI 모델로 구성된다.  
주요 기능은 회원가입, 로그인, 진단 서비스, 맞춤형 문제 추천, 생성형 AI 문제, 대시보드, 교수 대시보드로 이루어진다. 회원가입은 학번, 학교, 학과, 이름, 휴대폰 인증, 소셜 로그인(카카오, 네이버, 구글) 지원을 포함하되, 테스트 기간 동안은 소셜 로그인을 활성화하지 않을 계획이다. 로그인은 ID/비밀번호, 소셜 로그인, 로그인 유지 기능을 제공한다. 진단 서비스는 최초 이용 시 진단 테스트로 학습 수준을 분석하며, 30문항의 고정 문제가 제공된다. 이 과정에서 산술식이 적용된다. 맞춤형 문제 추천은 진단 결과와 학습 이력을 기반으로 AI가 추천하며, 산술식과 더불어 PDF를 통한 LLM 학습을 바탕으로 AI 추천 문제가 제공된다. 교수의 허가 없이 AI가 생성한 문제는 문제가 될 수 있으므로, AI가 생성 후 교수의 허가를 받지 않은 경우에는 PDF에서 문제를 추출해와야 하며, 이때 라벨링 로직이 사용될 수 있다. 생성형 AI 문제는 Exaone Deep 모델을 통한 실시간 문제 생성 기능으로, 역시 PDF를 통한 LLM 학습을 바탕으로 문제를 생성하는 로직이 적용된다. 대시보드는 풀이 이력, 정답률, 추천 문제 현황, 피드백을 제공하며, 교수 대시보드는 강의 배정, 학생 학습 정보 확인, 과제 및 문제 업로드, AI 학습 관리, 문제 생성 기능을 포함한다.  
데이터베이스 구조는 사용자 정보(users 테이블), 인증 정보(verifications 테이블), 문제 벡터(problems 테이블, pgvector 활용), 진단 및 테스트(test\_sessions, test\_responses 테이블), 교수/강의(courses, course\_students 테이블), 변조 방지(knowledge\_audit 테이블, SHA3-512 해시 체인)로 구성된다.  
데이터 흐름은 프론트엔드(React)에서 백엔드(FastAPI)로, 다시 DB(PostgreSQL/pgvector)와 AI 모델(EXAONE)로 이어진다. 외부 API(공공데이터포털, SMS 인증 등)와 연동되며, 모든 데이터 변경 이력은 블록체인 해시 체인으로 기록된다. 시간이 허락된다면, 백엔드의 로직과 기술에 대해 경복대학교 AI 튜터 시스템의 자체 API를 공유하여 프론트엔드 또는 팀원들이 사용하기 쉽게 개발할 계획이다.  
AI 모델은 EXAONE Deep을 서버 로컬에 배포하여 외부 API 의존성을 최소화한다. 문제 임베딩, AI 문제 생성, 진단 결과 분석 등에 활용되며, 모델 버전 고정, 입력/출력 검증, 리소스 제한 및 모니터링이 적용된다.  
보안 및 품질 관리는 JWT 기반 인증, OAuth 2.0 소셜 로그인, 4계층 암호화(전송, 저장, 메모리, 프로세스), 역할 기반 접근 제어(학생, 교수, 관리자), 주기적 체크섬 검증 및 자동 롤백, Prometheus 및 Grafana를 통한 실시간 모니터링을 포함한다.  
CampusON 프로젝트의 성공 조건은 모든 핵심 기능의 정상 동작과 사용자 만족도 확보, 데이터 무결성, 보안, 성능 기준 충족, 문서화 및 유지보수 용이성 보장 등으로 요약된다.  
여러 PDF 파일(문제지와 가답안)을 자동으로 인식하고, 같은 연도와 과목의 파일을 정확하게 매칭하여 문제와 정답 정보를 JSON 형태로 저장하는 과정에서는 파일명이 다르거나 불규칙할 때도 자동 매칭이 잘 이뤄지도록 파일명 전처리나 유사도 기반 매칭 로직을 도입할 필요가 있다. 파일 수가 많아질수록 과부하나 매칭 실패가 발생하지 않도록 효율적이고 확장성 있는 파일 매칭 및 파싱 시스템을 설계해야 하며, 웹사이트에서 사용자가 PDF 파일을 업로드할 때도 오류 없이 자동으로 매칭과 파싱이 이뤄지게 견고한 로직을 미리 만들어야 한다. 추가적으로, text\_json에서 vector\_json, 그리고 postgresql로 데이터가 이동하는 흐름을 고려해야 한다. 다양한 로직과 함께 Fuzzy, 매칭률, 문제 인식률, 산술식 등 서브 기술들을 각각 설정하는 것은 추후 유지보수와 확장에 도움이 될 것이다.  
학생의 초기 수준 진단을 위한 산술식을 어떻게 설계해야 진단테스트 결과를 신뢰성 있게 수치화할 수 있을지에 대한 고민도 있다. 산술식이 정확해야 진단테스트 후 학생에게 맞는 난이도의 문제를 추천할 수 있고, 빅데이터 기반 시각화 및 분석에도 활용할 수 있기 때문에 산식의 형태와 적용 방법을 명확히 정해야 한다. 또한 진단테스트 기능에 이 산술식을 어떻게 연동할지, 향후 IRT나 AI 기반 평가 등으로 확장하는 방안까지 고려해 설계해야 한다. 임시로 설계된 산술식은 다음과 같다. 학습수준지표는 (정답1 × 난이도점수1 \+ 정답2 × 난이도점수2 \+ ... \+ 정답n × 난이도점수n) / (난이도점수1 \+ 난이도점수2 \+ ... \+ 난이도점수n)으로, 여기서 정답i는 i번째 문제의 정답 여부(정답이면 1, 오답이면 0), 난이도점수i는 i번째 문제의 난이도 점수(예: 쉬움=1, 보통=2, 어려움=3 등), n은 전체 문제 수를 의미한다.  
마지막으로, PDF 파서에서 추출한 문제와 정답 데이터를 벡터 형태로 변환하여 LLM이 학습할 수 있도록 하고, 검색 효율도 높이고자 한다. 문제의 난이도나 유형을 AI가 자동으로 라벨링할 수 있는 로직을 파서 결과(JSON 또는 DB)에 어떻게 적용할지, LLM이 문제의 난이도, 유형, 개념 등을 인식하고 자체적으로 라벨링하는 방식의 정확도와 신뢰성을 어떻게 높일 수 있을지, 그리고 이 과정에서 사람이 개입해야 할 부분이 어디까지일지에 대해서도 함께 고민하고 있다.

## 산술식에 대하여

학습수준지표 산술식은 진단 테스트 문항에 대한 학생의 응답을 바탕으로, 학생의 현재 지식 숙련도를 정량적으로 평가하기 위해 고안된 평가 도구이다. 이 산술식은 각 문항의 정답 여부와 해당 문항의 난이도 점수를 곱하여 합산하고, 이를 전체 문항의 난이도 점수 총합으로 나누는 방식으로 계산된다. 이러한 구조는 단순히 정답 개수만을 집계하는 것이 아니라, 각 문항이 가진 상대적 난이도까지 반영함으로써 학생의 학습 수준을 보다 정교하게 측정할 수 있도록 설계되었다.  
수학적으로 이 산술식은 다음과 같이 표현된다. 각 문항의 정답 여부를 *Ci*라 하고, 정답일 경우 1, 오답일 경우 0으로 이진 값을 가진다. 각 문항의 난이도 점수는 *Di*로 표기하며, 이는 보통 쉬움, 보통, 어려움과 같은 등급에 따라 1, 2, 3 등으로 할당된다. 전체 문항 수를 *n*이라고 할 때, 학습수준지표는 (C1×D1+C2×D2+...\+*Cn*×*Dn*)*/(D1\+D2\+...+Dn)*의 형태로 산출된다. 이 결과값은 0에서 1 사이의 실수로 나타나며, 1에 가까울수록 학생이 높은 난이도의 문제까지 정확히 해결했음을 의미한다.  
실제 계산 과정은 다음과 같다. 먼저, 학생이 응답한 각 문항에 대해 정답 여부(0 또는 1)와 해당 문항의 난이도 점수를 곱한다. 그 결과값들을 모두 더한 후, 전체 문항의 난이도 점수 합으로 나눈다. 예를 들어, 5개의 문항이 각각 난이도 1, 2, 3, 2, 1점으로 설정되어 있고, 학생이 1번, 3번, 5번 문항만 맞혔다면, 분자는 (1×1)+(0×2)+(1×3)+(0×2)+(1×1)=5가 되고, 분모는 1+2+3+2+1=9가 되어 학습수준지표는 5/9, 즉 약 0.56이 된다.  
이 산술식의 수학적 구조는 가중평균(Weighted Average) 방식과 유사하다. 각 문항의 난이도 점수가 가중치로 작용하며, 정답 여부가 1일 때만 해당 가중치가 누적된다. 따라서 쉬운 문제(난이도 점수 1)를 맞혔을 때보다 어려운 문제(난이도 점수 3)를 맞혔을 때 학습수준지표에 더 큰 영향을 미친다. 이는 학생이 단순히 정답률이 높더라도, 쉬운 문제만 맞힌 경우와 어려운 문제까지 해결한 경우를 명확히 구분할 수 있게 해준다.  
학생에게 제공되는 학습수준지표의 값은 일반적으로 소수점 둘째 자리까지의 실수(예: 0.78)로 표기되거나, 0\~100%의 백분율(예: 78%)로 변환하여 표시할 수 있다. 이 값은 대시보드 등 시각화 도구를 통해 학생 본인과 교사가 직관적으로 확인할 수 있도록 제공된다. 예를 들어, ‘현재 학습수준지표: 0.62(62%)’와 같이 표시되며, 최근 진단 테스트 결과와 비교하여 상승 또는 하락 추이를 그래프로 나타낼 수도 있다.  
이 산술식은 진단 테스트의 결과를 신뢰성 있게 수치화할 뿐만 아니라, 학생별로 적합한 난이도의 문제를 추천하는 데에도 활용된다. 학습수준지표가 일정 기준 이상인 학생에게는 더 높은 난이도의 문제를, 기준 미만인 학생에게는 기초 문제를 우선적으로 제공하는 방식으로 적응형 학습 경로를 설계할 수 있다. 또한, 여러 차례 진단 테스트 결과를 시계열 데이터로 누적하여, 학생의 성장 곡선이나 학습 곡선을 분석할 수도 있다. 이때 학습 곡선은 초기에는 급격한 상승을 보이다가 점차 완만해지는 ‘감소수익형 곡선’이나, 초반에는 완만하다가 점차 급격히 상승하는 ‘증가수익형 곡선’ 등 다양한 형태로 나타날 수 있다.  
실제 구현에서는 스프레드시트 소프트웨어의 SUMPRODUCT 함수 등을 활용해 손쉽게 시뮬레이션이 가능하다. 예를 들어, 각 문항의 정답 여부와 난이도 점수를 각각의 셀에 입력한 후, SUMPRODUCT(정답범위, 난이도범위)/SUM(난이도범위)와 같은 수식으로 자동 계산할 수 있다. 이처럼 구조가 단순하고 해석이 용이하기 때문에, AI 튜터링 시스템의 초기 도입 단계에서 신속하게 적용할 수 있다.  
향후에는 이 산술식에 시간 가중치, 최근 응답 가중치, 문항별 변별도 등 추가적인 요소를 반영하여 더욱 정교한 평가 모델로 확장할 수 있다. 또한, 누적된 진단 결과를 바탕으로 학생별 성장률(예: 최근 2회 진단의 평균 상승폭)이나 목표치 도달 여부(예: 목표 지표 0.8 도달 여부)를 함께 제공함으로써, 학생과 교사가 학습 성과를 다각적으로 분석할 수 있다.  
결론적으로, 학습수준지표 산술식은 정답률과 문항 난이도를 결합하여 학생의 학습 숙련도를 명확하고 수학적으로 타당하게 정량화할 수 있는 방법을 제공한다. 이 산술식은 학생 개인의 강점과 약점을 구체적으로 파악하고, 맞춤형 학습 경험을 지원하는 데 중요한 역할을 하며, 향후 데이터 기반의 교육 혁신을 위한 기반 지표로 활용될 수 있다.

## 주요 로직 : 유저 향상력

AI 튜터 시스템에서 학생의 학습 수준이 문제 풀이를 통해 어떻게 변화하고 향상되는지를 모델링하는 것은 매우 중요한 연구 주제이다. 기존에는 베이지언 기반의 지식 추적 모델, 예를 들어 Knowledge Tracing이나 IRT(Item Response Theory)와 같은 방식이 널리 활용되어 왔다. 하지만 최근에는 베이지언 접근법 이외에도 다양한 로직과 기술이 개발되고 있으며, 이들 각각은 학습 데이터의 특성, 시스템의 목적, 그리고 실제 적용 환경에 따라 선택적으로 활용될 수 있다. 학생의 학습 수준 향상 모델링을 위해 가장 기본적으로 고려할 수 있는 방법은 산술적 가중평균 방식이다. 이 방식에서는 학생이 각 문제를 풀 때마다 해당 문제의 난이도와 정답 여부를 기록하고, 이를 누적하여 학습 수준을 산출한다. 예를 들어, 각 문제의 정답 여부(1 또는 0)와 난이도 점수(예: 1, 2, 3 등)를 곱한 값을 누적하고, 전체 난이도 점수의 합으로 나누는 방식이다. 이 결과값은 0에서 1 사이의 실수로 나타나며, 학생이 어려운 문제까지 맞힐수록 더 높은 점수를 얻게 된다. 이와 같은 산술식은 구현이 간단하고 직관적이어서, 대규모 시스템의 초기 도입이나 신속한 피드백 제공에 적합하다. 이와 더불어, 최근에는 딥러닝 기반의 시계열 모델을 활용한 학습 수준 추적 방식이 각광받고 있다. 대표적으로 DKT(Deep Knowledge Tracing)와 같은 모델은 학생의 문제 풀이 이력을 시계열 데이터로 받아들여, LSTM(Long Short-Term Memory)과 같은 순환 신경망 구조를 통해 시간에 따라 변화하는 학생의 지식 상태를 예측한다. 이러한 방식은 학생이 어떤 개념을 반복적으로 접하거나, 특정 유형의 문제에서 오답을 반복하는 경우에도 그 패턴을 학습하여, 미래의 정답 확률을 동적으로 추정할 수 있다는 장점이 있다. 또한, 최근에는 Transformer 기반의 시계열 모델도 연구되고 있어, 대용량 학습 데이터와 복잡한 개념 구조를 가진 환경에서도 높은 예측 성능을 보이고 있다. 또 다른 방식으로는 규칙 기반(Heuristic) 또는 룰 베이스드(Rule-based) 모델이 있다. 이 방식은 예를 들어, 최근 5문제 중 4개 이상을 맞히면 다음 단계로 이동하거나, 특정 유형에서 연속 오답이 발생할 경우 해당 유형을 집중적으로 반복 학습하도록 설계하는 것이다. 이러한 방식은 해석이 쉽고, 실제 교육 현장에서 교사와 학생이 이해하기 쉬운 피드백을 제공할 수 있다는 점에서 장점이 있다. 다만, 세밀한 수준 구분이나 복잡한 학습 경로 설계에는 한계가 있을 수 있다. 학생의 학습 수준이 문제 풀이를 통해 어떻게 변화하는지에 대한 로직은, 실제로는 여러 방식이 혼합되어 적용될 수 있다. 예를 들어, 초기에 산술식 기반의 학습 수준 지표로 빠른 피드백을 제공하다가, 데이터가 누적되면 딥러닝 기반의 시계열 예측 모델로 전환하거나, 특정 상황에서는 룰 베이스드 로직을 병행 적용하는 식이다. 이러한 통합적 접근은 시스템의 신뢰성과 확장성을 높이는 데 기여한다. 문제 풀이 과정에서 저장되는 데이터는 학생의 ID, 문제 번호, 문제 유형, 난이도, 정답 여부, 풀이 시간, 오답 유형 등 다양한 항목을 포함한다. 이 데이터는 데이터베이스에 실시간으로 누적 저장되며, 이후 학습 수준 산출, 오답 패턴 분석, 추천 문제 선정, 학습 경로 설계 등 다양한 기능에 활용된다. 예를 들어, 학생이 한 문제를 풀 때마다 해당 결과가 즉시 저장되고, 전체 학습 이력과 함께 실시간으로 학습 수준 지표가 갱신된다. 이 과정에서 데이터는 JSON, CSV, 혹은 관계형 데이터베이스 형태로 저장될 수 있으며, 대규모 시스템에서는 효율적인 조회와 분석을 위해 벡터 데이터베이스나 분산 저장 기술이 활용되기도 한다. 기술적으로는 Python 기반의 FastAPI와 같은 웹 프레임워크, PostgreSQL 및 pgvector와 같은 데이터베이스, 그리고 PyTorch, TensorFlow 등 딥러닝 프레임워크가 주로 활용된다. 백엔드에서는 RESTful API를 통해 프론트엔드와 데이터를 주고받으며, AI 모델은 서버 로컬 또는 클라우드 환경에서 동작하게 된다. 실시간 분석과 대시보드 제공을 위해서는 데이터 스트리밍 및 비동기 처리 기술, 그리고 시각화 도구가 함께 사용된다. 결과적으로, AI 튜터의 학습 수준 향상 모델링 로직은 산술식 기반의 단순 모델부터 딥러닝 기반의 시계열 예측, 그리고 규칙 기반의 보완 로직까지 다양하게 구성될 수 있다. 각 방식은 구현의 난이도, 데이터 요구량, 해석 가능성, 실시간성 등에서 차이가 있으며, 실제 시스템에서는 이들 로직을 목적과 환경에 맞게 조합하여 적용하는 것이 바람직하다. 이러한 모델링을 통해 학생 개개인의 학습 성장 과정을 정량적으로 추적하고, 맞춤형 학습 피드백과 추천을 제공함으로써, 궁극적으로 학습 효과를 극대화할 수 있다.

## API 에 따른 파일 연동

대규모 AI 튜터 백엔드 시스템에서 각 파일과 모듈이 어떻게 연결되는지, 그리고 API와 데이터 흐름이 어떻게 구성되는지에 대해 설명한다. 이 구조는 Python의 FastAPI와 PostgreSQL, 그리고 AI 모델 및 벡터 데이터베이스를 사용하는 현대적인 백엔드 아키텍처를 기준으로 한다.  
백엔드의 전체 구조는 크게 애플리케이션 진입점, 라우팅, 컨트롤러, 서비스, 모델, 데이터베이스, 설정, 유틸리티, 미들웨어 등으로 나뉜다. 프로젝트 루트에는 보통 app 또는 src라는 메인 폴더가 생성되고, 그 아래에 각 기능별 하위 디렉토리가 배치된다. 가장 먼저 app/main.py 파일이 존재하며, 이 파일은 FastAPI 인스턴스를 생성하고, 전체 프로젝트의 진입점 역할을 한다. main.py에서는 라우팅 모듈을 import하여 FastAPI 객체에 등록한다. 예를 들어, app/api/v1/users.py와 같은 라우팅 파일이 있을 경우, main.py에서 해당 라우트 파일을 포함시켜 API 엔드포인트가 활성화된다. 라우팅 파일은 실제로 각 API 엔드포인트(URL 경로)를 정의하고, 각 요청이 들어왔을 때 어떤 컨트롤러 함수가 실행될지 지정한다. 예를 들어, /users 경로로 GET 요청이 들어오면 user\_controller의 get\_user 함수가 호출된다. 라우트 파일은 app/api/v1/와 같이 버전별로 관리될 수 있으며, 각 라우트 파일은 관련된 컨트롤러를 import해서 사용한다. 컨트롤러는 실제 요청에 대한 비즈니스 로직을 담당한다. 컨트롤러 함수는 서비스 계층의 함수들을 호출하여 데이터 처리, 검증, 예외 처리 등을 수행한 뒤, 최종적으로 응답 데이터를 반환한다. 예를 들어, user\_controller.py는 user\_service.py의 get\_user\_by\_id 함수를 호출하여 데이터베이스에서 사용자 정보를 조회하고, 이를 가공하여 반환한다.  
서비스 계층은 컨트롤러와 모델 사이에서 복잡한 비즈니스 로직을 수행한다. 예를 들어, 학생의 진단 결과를 바탕으로 학습 수준을 계산하거나, 추천 문제 리스트를 생성하는 알고리즘이 이 계층에 위치한다. 서비스 계층은 여러 모델을 조합하여 데이터를 처리하거나, 외부 AI 모델과 통신하는 역할도 수행한다. 모델 계층은 데이터베이스와 직접적으로 상호작용한다. SQLAlchemy, SQLModel, Pydantic 모델 등이 이 계층에 위치하며, 데이터베이스의 테이블 구조와 데이터 타입을 정의한다. 예를 들어, User, Problem, TestSession, TestResponse 등 각종 데이터 엔터티가 models 폴더에 정의된다. 모델 계층은 서비스 계층에서 호출되어 데이터의 생성, 조회, 수정, 삭제 작업을 수행한다. 데이터베이스 연결 및 세션 관리는 db/database.py와 같은 파일에서 담당한다. 이 파일은 PostgreSQL 데이터베이스와의 연결 설정, 세션 생성, 커넥션 풀 관리 등을 수행한다. 또한, Alembic과 같은 마이그레이션 도구를 통해 테이블 구조 변경 및 버전 관리를 지원한다. 설정 파일(config.py)은 환경 변수와 각종 설정값을 관리한다. 예를 들어, 데이터베이스 접속 정보, 비밀키, 외부 API 키, AI 모델 경로 등이 이 파일에 정의된다. .env 파일을 통해 실제 환경 변수 값을 주입받아 config.py에서 읽어들이는 구조를 갖는다. 유틸리티 함수들은 utils.py 또는 utils/ 폴더에 위치하며, 공통적으로 자주 사용하는 함수나 클래스(예: 토큰 생성, 암호화, 파일명 전처리, 유사도 계산 등)가 이곳에 모인다.  
미들웨어 계층은 요청과 응답의 흐름을 가로채서 로깅, 인증, 에러 핸들링, CORS 처리 등을 담당한다. 미들웨어는 app/main.py에서 FastAPI 인스턴스에 등록되어 전체 트래픽에 적용된다. AI 관련 로직은 보통 services/ai\_service.py 또는 algorithms/ 폴더에 위치한다. 예를 들어, 진단 테스트 산술식 계산, 문제 벡터화, LLM을 통한 문제 라벨링, 추천 알고리즘 등이 이 계층에 구현된다. 이 로직들은 서비스 계층에서 호출되어, 학생의 학습 이력과 진단 결과를 바탕으로 AI 모델을 실행하고 결과를 반환한다. API의 데이터 흐름은 다음과 같다. 사용자가 프론트엔드(React 등)에서 요청을 보내면, FastAPI의 라우트가 해당 요청을 받아 컨트롤러 함수로 전달한다. 컨트롤러는 필요한 경우 서비스 계층의 함수를 호출하여 비즈니스 로직을 처리하고, 모델 계층을 통해 데이터베이스에서 데이터를 읽거나 쓴다. AI 연산이 필요한 경우 서비스 계층에서 AI 서비스 모듈을 호출하여 결과를 얻는다. 최종적으로 컨트롤러는 응답 데이터를 만들어 라우트로 반환하고, FastAPI가 이를 프론트엔드로 전달한다. 예를 들어, 학생이 진단 테스트 결과를 조회하는 경우, 프론트엔드에서 /api/v1/diagnosis/result 엔드포인트로 요청을 보낸다. FastAPI 라우트가 이를 받아 diagnosis\_controller.py의 get\_result 함수를 호출한다. 이 함수는 diagnosis\_service.py의 calculate\_learning\_level 함수를 호출하여, models/test\_response.py에서 학생의 응답 데이터를 조회하고, algorithms/learning\_level.py에서 산술식을 적용해 학습 수준을 계산한다. 그 결과는 컨트롤러를 통해 JSON 형태로 응답된다.  
이와 같은 계층적 구조와 파일 간 연결 방식은 유지보수성과 확장성을 높이며, 각 파일이 어떤 역할을 하고 어디에 연결되어 있는지 명확하게 파악할 수 있도록 한다. 또한, API 문서화(OpenAPI/Swagger)와 테스트 코드가 함께 작성되어, 전체 시스템의 품질과 신뢰성을 높이는 데 기여한다.

## PDF 파서에 대하여

PDF 파서는 PDF 문서에서 텍스트와 메타데이터를 추출하는 도구로, Apache Tika는 이 작업을 위한 대표적인 오픈소스 라이브러리 중 하나이다. Tika는 다양한 파일 포맷을 자동으로 감지하고, PDF를 포함한 여러 문서에서 텍스트와 구조적 정보를 효과적으로 추출할 수 있다. 기본적으로 Tika는 PDFParser나 AutoDetectParser와 같은 클래스를 활용하여 PDF 파일의 본문 텍스트, 작성자, 생성일, 페이지 수 등 다양한 메타데이터를 추출한다. 예를 들어, BodyContentHandler로 본문 텍스트를 받고, Metadata 객체에 문서의 속성을 저장하며, ParseContext로 파서의 동작을 제어할 수 있다.  
Tika의 PDF 파싱은 일반적으로 비암호화된 디지털 PDF에서 가장 효과적이며, 암호화된 경우에도 메타데이터에 비밀번호를 제공하면 처리할 수 있다. 또한, PDF 내부에 포함된 첨부파일이나 이미지 등도 추출이 가능하다. 단, PDF의 표 구조는 대부분의 경우 명시적으로 저장되어 있지 않기 때문에, 표의 셀 경계나 행 구조를 완벽하게 복원하는 것은 어렵다. Tika는 기본적으로 표 내 텍스트를 추출하지만, 표 구조 자체를 인식하거나 재구성하지는 않는다. 복잡한 표 구조가 필요한 경우에는 Tabula와 같은 별도의 라이브러리와 연동이 필요하다.  
Tika를 활용한 PDF 파싱의 기본 흐름은 다음과 같다. 먼저, PDF 파일을 입력 스트림으로 읽어들인다. AutoDetectParser 또는 PDFParser 객체를 생성하여 파싱 작업을 수행하며, BodyContentHandler로 텍스트를 받고, Metadata 객체로 메타데이터를 수집한다. 파싱이 완료되면 handler.toString()을 통해 본문 텍스트를, metadata.get(name)으로 각종 속성 정보를 얻을 수 있다.  
향후 CampusON과 같은 AI 튜터 시스템에서 PDF 파서를 활용할 때는 단순 텍스트 추출을 넘어, 문제와 정답, 난이도, 유형 등 구조화된 정보로의 변환이 필요하다. 이를 위해서는 텍스트 내에서 문제 번호, 선택지, 정답 패턴 등을 정규표현식이나 추가 알고리즘으로 식별하고, JSON 등 표준화된 데이터 구조로 저장하는 기능이 요구된다. 또한, 여러 PDF 파일을 한 번에 처리하는 경우 파일명 전처리, 유사도 기반 매칭, 과부하 방지 등 추가적인 로직이 필요하다.  
기능 확장을 위해서는 파서 단계에서 추출된 텍스트를 LLM(대형 언어 모델)이나 추가 AI 알고리즘과 연동하여, 문제 유형 자동 분류, 난이도 추정, 태깅 등 고차원적 정보 추출이 가능하도록 설계할 수 있다. 예를 들어, 파서가 추출한 텍스트를 벡터화하여 데이터베이스에 저장하고, 검색이나 추천 시스템과 연계하는 방식이 가능하다. 또한, 추출 과정에서 오류나 누락이 발생할 경우, 로그 기록, 예외 처리, 관리자 검수 등 신뢰성을 높이기 위한 기능도 함께 구축해야 한다.  
요약하면, Apache Tika 기반의 PDF 파서는 다양한 문서에서 텍스트와 메타데이터를 효과적으로 추출할 수 있으며, CampusON 프로젝트에서는 단순 추출을 넘어 구조화, 자동 라벨링, 대량 파일 처리, AI 연동 등 기능적 요소를 점진적으로 확장하는 알고리즘 설계가 필요하다.

## 공개 API 서버

CampusON 프로젝트에서는 팀원 간의 효율적인 협업과 개발 생산성 향상을 위해 “공개 API 서버”를 별도로 구축 및 운영한다. 이 서버는 FastAPI를 기반으로 하며, 팀원들이 정해진 도메인 또는 네트워크 환경에서만 접근할 수 있도록 보안과 접근 제어를 강화한 형태로 설계된다. 이를 통해 각 팀원은 개별 개발 환경에 상관없이 동일한 API 엔드포인트를 활용하여 데이터베이스 구조 확인, PDF 파서 테스트, 신규 기능 검증 등 다양한 개발 및 테스트 작업을 수행할 수 있다.  
공개 API 서버는 다음과 같은 주요 목적을 가진다. 첫째, 프로젝트의 핵심 기능(API 엔드포인트, 데이터베이스 구조, PDF 파서 등)을 중앙집중화하여 팀원 모두가 일관된 환경에서 개발 및 테스트를 진행할 수 있도록 한다. 둘째, Swagger(OpenAPI) 기반의 자동 문서화 및 인터랙티브 테스트 환경을 제공함으로써, 엔드포인트별 요청/응답 구조, 파라미터, 데이터 포맷, 예외 코드 등을 직관적으로 확인하고 실시간으로 테스트할 수 있게 한다. 셋째, 접근 제어 정책을 적용하여, 지정된 도메인 또는 IP에서만 API 서버에 접속할 수 있도록 함으로써 외부 노출을 최소화하고, 내부 정보 유출 및 무단 접근을 방지한다.  
API 서버의 접근 제어는 CORS 정책, 미들웨어 기반의 요청 헤더 및 IP 필터링, 네트워크 방화벽 등 다양한 계층에서 이루어진다. 예를 들어, FastAPI의 CORSMiddleware를 활용하여 허용된 Origin만 접근 가능하도록 설정하거나, 미들웨어에서 요청의 Host, X-Forwarded-For, 혹은 커스텀 헤더(API Key 등)를 검사하여 인증된 팀원만 접근을 허용한다. 추가적으로, 클라우드 환경에서는 방화벽이나 로드밸런서에서 허용 IP/도메인을 지정하여 네트워크 단위로 접근을 제한할 수 있다.  
API 서버의 핵심 엔드포인트에는 데이터베이스 구조 조회, PDF 파서 테스트, 진단 산술식 테스트, 사용자 인증, 데이터 조회 및 입력 등이 포함된다. 각 엔드포인트는 Swagger UI를 통해 자동 문서화되며, 팀원들은 웹 브라우저, Postman, curl 등 다양한 도구로 직접 요청을 보내고 응답을 확인할 수 있다. 이를 통해 실제 서비스 환경과 동일한 조건에서 기능을 검증하고, 문제 발생 시 신속하게 원인을 파악할 수 있다.  
API 서버의 보안 및 운영 측면에서는, JWT 또는 API Key 기반의 인증 방식을 적용하여 팀원별 접근 권한을 세분화할 수 있다. 또한, 모든 요청 및 응답은 로그로 기록되어, 추후 문제 발생 시 감사 및 추적이 가능하다. 서버의 상태, 사용량, 에러율 등은 Prometheus, Grafana 등 모니터링 도구를 통해 실시간으로 관리된다.  
공개 API 서버는 프로젝트의 개발, 테스트, 유지보수 전 과정에서 핵심적인 역할을 하며, 팀원 간의 원활한 소통과 신속한 피드백, 그리고 안정적인 서비스 품질 확보에 기여한다. 또한, 향후 외부 파트너나 확장 개발 시에도 동일한 구조와 정책을 적용하여, 보안성과 효율성을 모두 갖춘 API 서비스로 발전시킬 수 있다.  
추가적으로, API 서버의 보안과 운영 효율성을 높이기 위해 다음과 같은 업계 권장 사항 및 기술적 요소를 반영한다. 첫째, 모든 API 요청 및 응답 데이터는 HTTPS를 통한 암호화로 보호되며, 민감한 데이터는 저장 시에도 암호화된다[7](https://www.ninjaone.com/blog/8-best-practices-for-securing-apis/). 둘째, API 엔드포인트별로 버전 관리가 이루어져, 다양한 버전의 API가 동시에 운영될 수 있고, 버전별로 점진적 폐기가 가능하다. 셋째, Role-Based Access Control(RBAC)을 도입하여, 관리자, 개발자, 일반 사용자 등 역할별로 접근 권한을 세분화하고, 각 역할에 따라 허용되는 기능과 데이터 범위를 명확히 구분한다. 넷째, API 사용량에 대한 모니터링과 로깅이 상시 이루어지며, 이상 징후나 비정상 트래픽 발생 시 즉각적인 탐지 및 대응이 가능하도록 한다. 다섯째, API 키, OAuth2, JWT 등 다양한 인증 및 권한 부여 방식을 지원하여, 외부 파트너나 추가 서비스 연동 시에도 유연하게 대응할 수 있다. 여섯째, Rate Limiting(요청 제한) 정책을 도입해 비정상적 트래픽이나 DoS 공격으로부터 API 서버를 보호한다. 마지막으로, API Gateway, WAF, 네트워크 방화벽 등 인프라 레벨의 보안 장치를 병행 적용하여 전체 시스템의 보안성을 강화한다.  
이러한 정책과 기술적 기반 위에서 CampusON의 공개 API 서버는 신뢰성, 보안성, 확장성을 모두 갖춘 개발 및 운영 환경을 제공하며, 프로젝트의 장기적 성장과 외부 협력까지도 안정적으로 지원할 수 있다.

## AI 사용 관련

CampusON 프로젝트에서 백엔드와 프론트엔드의 구조를 명확하게 설계하는 가장 큰 이유 중 하나는, 초기 개발 단계에서는 빠른 프로토타이핑과 서비스 제공을 위해 외부 AI API(예: OpenAI, 클라우드 LLM API 등)를 적극 활용하고, 이후 서비스가 안정화되고 데이터가 충분히 쌓이면 자체 AI 모델(예: Ollama, Llama Studio 등)로 전환할 계획이기 때문이다. 이러한 전략은 개발 속도와 서비스 품질, 그리고 장기적인 비용 및 데이터 보안 측면에서 모두 중요한 의미를 가진다.  
우선, 외부 AI API를 활용하면 복잡한 모델 구축이나 인프라 운영 없이도 최신 AI 기능을 빠르게 도입할 수 있다. 프론트엔드와 백엔드는 RESTful API, OpenAPI, Swagger 등 표준화된 인터페이스 사양을 기반으로 통신하며, AI 서비스 역시 동일한 방식으로 연동된다. 이때, API 응답 포맷과 요청 구조를 명확히 정의하고 문서화함으로써, 프론트엔드와 백엔드, 그리고 AI 서비스 간의 데이터 흐름과 통합 테스트가 원활하게 이루어진다. 실제로는 FastAPI와 같은 백엔드 프레임워크를 통해 AI API에 대한 연동 모듈을 만들고, 프론트엔드에서는 해당 API 엔드포인트를 호출하여 결과를 받아 사용자에게 제공하는 구조가 된다.  
이러한 구조는 추후 자체 AI 모델로의 전환(마이그레이션) 시에도 큰 장점을 가진다. 예를 들어, Ollama나 Llama Studio와 같은 로컬 AI 모델은 OpenAI API와 거의 동일한 엔드포인트 및 응답 포맷을 제공한다. 따라서 백엔드에서 AI API의 엔드포인트 주소만 환경 변수나 설정 파일을 통해 바꿔주면, 기존 코드와 프론트엔드 로직을 거의 수정하지 않고도 손쉽게 자체 모델로 전환할 수 있다. 실제로 많은 오픈소스 AI 도구들은 로컬 모델 지원을 위해 OpenAI API와 호환되는 인터페이스를 제공하며, 엔드포인트 URL만 변경하면 로컬 환경에서도 동일한 방식으로 AI 기능을 사용할 수 있도록 설계되어 있다.  
이러한 설계는 데이터 보안, 비용 절감, 커스터마이징, 서비스 확장성 측면에서 매우 유리하다. 초기에는 클라우드 기반 AI API를 이용해 빠르게 서비스를 론칭하고, 사용량 증가 및 데이터 축적에 따라 Ollama, Llama Studio 등 자체 AI 모델로 전환함으로써 외부 의존성을 줄이고, 프라이버시와 운영비용을 동시에 개선할 수 있다. 또한, API 기반의 모듈화된 구조는 프론트엔드와 백엔드, AI 모델 간의 역할 분리를 명확히 하여, 각 파트의 독립적 개발과 유지보수를 용이하게 한다.  
마지막으로, AI 모델 마이그레이션 시에는 API 명세의 일관성 유지, 모델별 특성(파라미터, 입력/출력 형식 등) 문서화, 버전 관리, 테스트 자동화, 성능 모니터링 등 체계적인 이전 전략이 필요하다. GitLab, Cohorte, LinkedIn 등 다양한 사례에서도, 새로운 AI 모델로의 전환 시 API 호환성, 인프라 적합성, 피처 플래그, 단계적 롤아웃 등 Best Practice를 적용하고 있다.  
결론적으로, CampusON 프로젝트는 초기에는 외부 AI API를 활용해 빠르게 서비스를 구축하고, 서비스가 안정화되면 Ollama, Llama Studio 등 자체 AI 모델로 무리 없이 전환할 수 있도록, 프론트엔드와 백엔드, 그리고 AI 연동 구조를 표준 API 기반으로 설계하고 있다. 이러한 전략은 향후 AI 기술 변화와 데이터 정책, 운영 환경 변화에도 유연하게 대응할 수 있는 기반이 된다.

## 진단 테스트의 원리

진단 테스트는 학생에게 한 문제씩 화면에 순차적으로 제시하는 방식으로 진행됩니다. 각 문제는 고유한 문제 번호를 가지고 있으며, 이 번호는 문제 화면 상단이나 문제 영역 내 고정된 박스 형태로 표시됩니다. 학생은 문제 번호를 확인하면서 해당 문제에 대한 답안을 입력할 수 있습니다. 답안 입력 방식은 두 가지 주요 형태로 구현될 수 있습니다. 첫째, 문제 번호와 함께 고정된 입력 박스에 직접 답안을 타이핑하거나 선택하는 방식입니다. 둘째, 문제에 제시된 보기(네모 박스 등) 중에서 정답을 찾아 클릭하거나 선택하면, 선택된 답이 자동으로 답안란에 채워지는 방식입니다. 이러한 UI 설계는 학생이 문제 번호를 명확히 인지하고, 답안을 쉽게 입력할 수 있도록 도와주며, 오답 입력을 최소화하는 데 기여합니다. 또한, 각 답안은 내부적으로 문제 번호와 연동되어 데이터베이스에 저장되며, 실시간으로 정답 여부를 판단하고 학습 수준 산출에 활용됩니다.

┌──────────────────────────────────────────────────────────────┐  
│ 🎯 {subject} 진단 테스트  ⏰ {min}:{second}  👤 {name}         │  
│ ████████████░░░░░░░░░░ 답변완료: 12/30 (40%) | 📊 저장됨        │  
└──────────────────────────────────────────────────────────────┘

┌──────────────────────────────────────────────────────────────┐  
│ 1 A 2 OOO 3 OOO 4 OOO 5 OOO 6 OOO 7 OOO 8 OOO 9 OOO 10 OOO │        │ 11 OOO 12 OOO 13 OOO 14 OOO 15 OOO 16 OOO 17 OOO 18 OOO 19 OOO 20 OOO  
│ 21 OOO 22 OOO 23 OOO 24 OOO 25 OOO 26 OOO 27 OOO 28 OOO 29 OOO 30 OOO  
│ ████████████░░░░░░░░░░ 답변완료: 12/30 (40%) | 📊 저장됨        │  
└──────────────────────────────────────────────────────────────┘

┌─────────────────┬────────────────────────────────────────────┐  
│  📋 답안 선택표  │               📝 문제 영역                 │  
│                 │                                            │  
│  1️⃣ ②  6️⃣ ①   │  문제 7번 | 💡 중간 난이도                │  
│  2️⃣ ③  7️⃣ 🔴  │  ─────────────────────────────────────────  │  
│  3️⃣ ④  8️⃣ ②   │                                            │  
│  4️⃣ ①  9️⃣ ③   │  다음 중 스택(Stack)의 특징으로 옳은 것은? │  
│  5️⃣ ④  🔟 ①   │                                            │  
│                 │                                            │  
│  11 ②  16 ④   │                                            │  
│  12 🔴  17 ①   │                                            │  
│  13 ③  18 ②   │                                            │  
│  14 ④  19 ③   │                                            │  
│  15 ①  20 ①   │  💡 힌트: 데이터 구조의 입출력 순서를      │  
│                 │       생각해보세요                         │  
│  21 ②  26 ④   │                                            │  
│  22 🔴  27 ①   │  ┌─────────────────────────────────────┐   │  
│  23 ③  28 ②   │  │ 선택된 답안: 미선택                 │   │  
│  24 ④  29 ③   │  │ 답변 시간: 00:00                    │   │  
│  25 ①  30 ①   │  └─────────────────────────────────────┘   │  
│                 │                                            │  
│ 🔴 \= 미답       │  \[⬅️ 이전\] \[건너뛰기\] \[다음 ➡️\] \[💾 저장\] │  
│ ①②③④ \= 답안    │                                            │  
│ 🔒 \= 잠김       │                                            │  
└─────────────────┴────────────────────────────────────────────┘

┌──────────────────────────────────────────────────────────────┐  
│ 📊 빠른 상태 확인                                            │  
│ ✅ 답변완료: 12문항 | 🔴 미답: 18문항 | 💡 건너뛴: 0문항    │  
│ \[🔍 미답 문항으로\] \[📝 처음으로\] \[✅ 최종 제출\]              │  
└──────────────────────────────────────────────────────────────┘  
